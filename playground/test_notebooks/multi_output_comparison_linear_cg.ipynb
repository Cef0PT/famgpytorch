{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparing a conventional and linear cg Multioutput-Output GP",
   "id": "d986c7538ae6165c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:49:03.677344Z",
     "start_time": "2025-03-30T08:49:02.462596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "import famgpytorch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {torch.cuda.get_device_name(device) if device.type == 'cuda' else 'CPU'}.\")"
   ],
   "id": "6499fd3423e574a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on NVIDIA GeForce RTX 3080.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Set up some very simple training data\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_1 &= \\sin(2\\pi x) + \\epsilon \\\\\n",
    "y_2 &= \\cos(2\\pi x) + \\epsilon \\\\\n",
    "\\epsilon &\\sim \\mathcal{N}(0, 0.04)\n",
    "\\end{align}\n",
    "$$\n",
    "With training and test examples regularly spaced points in [0,1]"
   ],
   "id": "28601a995fe32cd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:49:03.790017Z",
     "start_time": "2025-03-30T08:49:03.682137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nb_training_points = 3000\n",
    "nb_test_points = 2000\n",
    "\n",
    "train_x = torch.linspace(0, 1, nb_training_points, device=device)\n",
    "\n",
    "train_y = torch.stack([\n",
    "    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size(), device=device) * math.sqrt(0.04),\n",
    "    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size(), device=device) * math.sqrt(0.04),\n",
    "], -1)"
   ],
   "id": "7d058d380727db1e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:49:03.942075Z",
     "start_time": "2025-03-30T08:49:03.926854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConventionalGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_inputs, train_targets, likelihood):\n",
    "        super(ConventionalGPModel, self).__init__(train_inputs, train_targets, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=2\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class LinearCGModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_inputs, train_targets, likelihood):\n",
    "        super(LinearCGModel, self).__init__(train_inputs, train_targets, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=2\n",
    "        )\n",
    "        self.covar_module = famgpytorch.kernels.MultitaskKernelLinearCG(\n",
    "            gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "conv_likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "conv_likelihood.to(device)\n",
    "conv_model = ConventionalGPModel(train_x, train_y, conv_likelihood)\n",
    "conv_model.to(device)\n",
    "\n",
    "linear_cg_likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "linear_cg_likelihood.to(device)\n",
    "linear_cg_model = LinearCGModel(train_x, train_y, linear_cg_likelihood)\n",
    "linear_cg_model.to(device)\n",
    "\n",
    "# initialize task kernel to make GPs comparable\n",
    "hypers = {\n",
    "    \"covar_module.task_covar_module.covar_factor\": torch.randn(2, 1, device=device),\n",
    "    \"covar_module.task_covar_module.raw_var\": torch.randn(2, device=device)\n",
    "}\n",
    "conv_model.initialize(**hypers)\n",
    "linear_cg_model.initialize(**hypers)\n",
    "None"
   ],
   "id": "89580b74a8551c9b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model",
   "id": "6efefb2c02d17a49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:50:04.868270Z",
     "start_time": "2025-03-30T08:49:03.950511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set models in training mode\n",
    "conv_model.train()\n",
    "linear_cg_model.train()\n",
    "conv_likelihood.train()\n",
    "linear_cg_likelihood.train()\n",
    "\n",
    "# use adam optimizer, including the GaussianLikelihood parameters\n",
    "conv_optimizer = torch.optim.Adam(conv_model.parameters(), lr=0.01)\n",
    "linear_cg_optimizer = torch.optim.Adam(linear_cg_model.parameters(), lr=0.01)\n",
    "\n",
    "# \"Loss\" for GPs - marginal log likelihood\n",
    "conv_mll = gpytorch.mlls.ExactMarginalLogLikelihood(conv_likelihood, conv_model)\n",
    "linear_cg_mll = gpytorch.mlls.ExactMarginalLogLikelihood(linear_cg_likelihood, linear_cg_model)\n",
    "\n",
    "print(\"Conventional:\")\n",
    "start = perf_counter()\n",
    "for i in range(50):\n",
    "    conv_optimizer.zero_grad()\n",
    "    conv_output = conv_model(train_x)\n",
    "    conv_loss = -conv_mll(conv_output, train_y)\n",
    "    conv_loss.backward()\n",
    "    if i == 0 or (i + 1) % 10 == 0:\n",
    "        task_noises = conv_model.likelihood.task_noises.tolist()\n",
    "        print(\n",
    "            f\"\\tIter {i + 1:02d}/50   \"\n",
    "            f\"Loss: {' ' if conv_loss.item() >= 0 else ''}{conv_loss.item():.3f}   \"\n",
    "            f\"lengthscale: {conv_model.covar_module.data_covar_module.lengthscale.item():.3f}   \"\n",
    "            f\"task_noises: {np.around(np.array(task_noises), 3).tolist()}   \"\n",
    "            f\"global_noise: {conv_model.likelihood.noise.item():.3f}\"\n",
    "        )\n",
    "    conv_optimizer.step()\n",
    "time_diff = perf_counter() - start\n",
    "print(f\"Taining in {time_diff:.3f} seconds.\")\n",
    "\n",
    "print(\"Linear CG\")\n",
    "start = perf_counter()\n",
    "for i in range(50):\n",
    "    linear_cg_optimizer.zero_grad()\n",
    "    linear_cg_output = linear_cg_model(train_x)\n",
    "    linear_cg_loss = -linear_cg_mll(linear_cg_output, train_y)\n",
    "    linear_cg_loss.backward()\n",
    "    if i == 0 or (i + 1) % 10 == 0:\n",
    "        task_noises = linear_cg_model.likelihood.task_noises.tolist()\n",
    "        print(\n",
    "            f\"\\tIter {i + 1:02d}/50   \"\n",
    "            f\"Loss: {' ' if linear_cg_loss.item() >= 0 else ''}{linear_cg_loss.item():.3f}   \"\n",
    "            f\"lengthscale: {linear_cg_model.covar_module.data_covar_module.lengthscale.item():.3f}   \"\n",
    "            f\"task_noises: {np.around(np.array(task_noises), 3).tolist()}   \"\n",
    "            f\"global_noise: {linear_cg_model.likelihood.noise.item():.3f}\"\n",
    "        )\n",
    "    linear_cg_optimizer.step()\n",
    "time_diff = perf_counter() - start\n",
    "print(f\"Taining in {time_diff:.3f} seconds.\")"
   ],
   "id": "177fd6756324e74b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional:\n",
      "\tIter 01/50   Loss:  1.128   lengthscale: 0.693   task_noises: [0.693, 0.693]   global_noise: 0.693\n",
      "\tIter 10/50   Loss:  1.093   lengthscale: 0.649   task_noises: [0.649, 0.649]   global_noise: 0.649\n",
      "\tIter 20/50   Loss:  1.052   lengthscale: 0.602   task_noises: [0.602, 0.603]   global_noise: 0.602\n",
      "\tIter 30/50   Loss:  1.011   lengthscale: 0.558   task_noises: [0.558, 0.558]   global_noise: 0.558\n",
      "\tIter 40/50   Loss:  0.969   lengthscale: 0.517   task_noises: [0.515, 0.516]   global_noise: 0.515\n",
      "\tIter 50/50   Loss:  0.927   lengthscale: 0.481   task_noises: [0.475, 0.476]   global_noise: 0.475\n",
      "Taining in 57.967 seconds.\n",
      "Linear CG\n",
      "\tIter 01/50   Loss:  1.128   lengthscale: 0.693   task_noises: [0.693, 0.693]   global_noise: 0.693\n",
      "\tIter 10/50   Loss:  1.096   lengthscale: 0.649   task_noises: [0.652, 0.663]   global_noise: 0.649\n",
      "\tIter 20/50   Loss:  1.056   lengthscale: 0.602   task_noises: [0.608, 0.615]   global_noise: 0.603\n",
      "\tIter 30/50   Loss:  1.015   lengthscale: 0.558   task_noises: [0.566, 0.57]   global_noise: 0.558\n",
      "\tIter 40/50   Loss:  0.973   lengthscale: 0.517   task_noises: [0.524, 0.526]   global_noise: 0.516\n",
      "\tIter 50/50   Loss:  0.932   lengthscale: 0.481   task_noises: [0.484, 0.485]   global_noise: 0.475\n",
      "Taining in 2.201 seconds.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Resulting covariance matrix",
   "id": "88a06b0fb7252ba7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:50:04.927640Z",
     "start_time": "2025-03-30T08:50:04.889257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\\nResulting covariance matrices\")\n",
    "    print(\"--Conventional--\")\n",
    "    conv_f_train = conv_model(train_x)\n",
    "    conv_train_covar = conv_f_train.covariance_matrix\n",
    "    print(conv_train_covar)\n",
    "\n",
    "    print(\"\\n--Linear CG--\")\n",
    "    linear_cg_f_train = linear_cg_model(train_x)\n",
    "    linear_cg_train_covar = linear_cg_f_train.covariance_matrix\n",
    "    print(linear_cg_train_covar)\n",
    "\n",
    "    rmse = torch.sqrt(torch.mean((conv_train_covar - linear_cg_train_covar) ** 2))\n",
    "    print(f\"\\nRMSE = {rmse.item():.3f}\")"
   ],
   "id": "f035d8af65cf88d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Resulting covariance matrices\n",
      "--Conventional--\n",
      "tensor([[ 1.4807, -1.5081,  1.4807,  ..., -0.1695,  0.1662, -0.1693],\n",
      "        [-1.5081,  2.7879, -1.5081,  ...,  0.3134, -0.1693,  0.3129],\n",
      "        [ 1.4807, -1.5081,  1.4807,  ..., -0.1698,  0.1664, -0.1695],\n",
      "        ...,\n",
      "        [-0.1695,  0.3134, -0.1698,  ...,  2.7879, -1.5081,  2.7879],\n",
      "        [ 0.1662, -0.1693,  0.1664,  ..., -1.5081,  1.4807, -1.5081],\n",
      "        [-0.1693,  0.3129, -0.1695,  ...,  2.7879, -1.5081,  2.7879]],\n",
      "       device='cuda:0', grad_fn=<MatmulBackward>)\n",
      "\n",
      "--Linear CG--\n",
      "tensor([[ 1.4807, -1.5072,  1.4807,  ..., -0.1696,  0.1664, -0.1693],\n",
      "        [-1.5072,  2.7843, -1.5072,  ...,  0.3133, -0.1693,  0.3128],\n",
      "        [ 1.4807, -1.5072,  1.4807,  ..., -0.1698,  0.1666, -0.1696],\n",
      "        ...,\n",
      "        [-0.1696,  0.3133, -0.1698,  ...,  2.7843, -1.5072,  2.7843],\n",
      "        [ 0.1664, -0.1693,  0.1666,  ..., -1.5072,  1.4807, -1.5072],\n",
      "        [-0.1693,  0.3128, -0.1696,  ...,  2.7843, -1.5072,  2.7843]],\n",
      "       device='cuda:0', grad_fn=<MatmulBackward>)\n",
      "\n",
      "RMSE = 0.001\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
